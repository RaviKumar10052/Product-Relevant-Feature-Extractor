"""
	Analyse the processed review data generated by process raw review data.py, to generate a file that contains features 
	ordered by thier product ids containing information about features present and a count of number of positive, negative,
	and neutral reviews corresponding to that review.
"""
from __future__ import division
from nltk.tokenize import RegexpTokenizer
from nltk import pos_tag
from nltk.corpus import stopwords
import sentiword_net_implementation as sni
from glob import glob
from re import compile, sub
from helper_functions import *
from reportlab.lib.units import cm
from reportlab.graphics.charts.piecharts import Pie
from reportlab.graphics.shapes import *
from reportlab.graphics import renderPDF

def main():
			# values to be initialised in constructor
	SWN_FILENAME = "SentiWordNet_3.0.0_20130122.txt"
	cv = sni.SentiWordNetCorpusReader(SWN_FILENAME)
	pos_sum = 0
	neg_sum = 0
	neu_sum = 0
	tokenizer = RegexpTokenizer(r"[\w\']+")
	get_tokens = tokenizer.tokenize
	stopwords_list = stopwords.words('english')
	f = open("tokenized_noun_file.txt", "r")
	final_file = open("output.txt", "w")
	feature_list, feature_name = [], []
	err_file = open("error_file.txt", "w")

	negation_list = ['don\'t', 'not', 'never']
			# tasks to be done in the constructor itself!

	subs_list = [compile("\'ve"), compile("\'d"), compile("\'s")]
	replace_list = ["have", "would", "is"]


	for i in f.readlines():
		feature = i.split(":")[0]
		feature_list.append(feature)
	f.close()
	# Start processing !!!
	hf = HelperFunctions(feature_list)
	tot_files = len(glob("list of products/*.txt"))
	product = hf.get_product_names()
	file_count = 0
	percent = 0
	print ("Analysing reviews for sentiments. Go to \'Progress Report.txt\' for further details")



	for filename in glob("list of products/*.txt"):
		progress_file = open("Progress Report.txt", "w")
		review_category = {}
		file_count += 1
		percent =  (file_count*100)//tot_files
		progress_file.write("Files Scanned: "+str(file_count)+"/"+str(tot_files) + "\n")
		progress_file.write("Progress: "+str(percent)+"%\n")
		progress_file.close()
		f = open(filename, "r")
		line = f.readline()
		reviews = []
		while line:
			reviews.append(line)
			line = f.readline()
		f.close()
		number_of_reviews = len(reviews)
		while len(reviews) > 0:
			review = reviews.pop(0)
			for i in range(3):
				review = subs_list[1].sub(replace_list[i], review)
			sentances = review.split(".")  						#splitting the review on the basis of fullstop.
			feature_score = {}									#processing each sentance for it's feature
			feature_adverb_score = {}
			final_sentances = []
			for i in sentances:
				if not i:
					continue
				final_sentances.extend(hf.check_for_but(i))   	# split the sentances having but in them to 2 diff sentances
			for t in final_sentances:							# scan the final set of sentances to check for features
				reverse_polarity = False
				counter = False
				tokens = get_tokens(t)
				pos_tagged_tokens = pos_tag(tokens)
				tokens_without_stop_words = []
				prev_feature = feature_name
				feature_name = hf.get_all_features(pos_tagged_tokens)  #extract features from review

				for i in feature_name:
					if i.strip(".,?/-").lower() not in review_category:   #Raghav change 'if not review_category.has_key(i.strip(".,?/-").lower())' to 'if i.strip(".,?/-").lower() not in review_category'
						review_category[i.strip(".,?/-").lower()] = {'pos_review':0, 'neg_review': 0, 'neutral_review': 0}

				if (t.find("it") != -1 or t.find("It") != -1) and not feature_name:
					feature_name = prev_feature
				for i in pos_tagged_tokens:    					#Remove the stop words!
					if (i[0].strip(".,?/-").lower() not in stopwords_list) or (i[0].strip(".,?/-").lower() == 'not'):
						tokens_without_stop_words.append(i)

				overall_pos_score, overall_neg_score = [], []
				overall_pos_score_adverb, overall_neg_score_adverb = [], []

				for i in tokens_without_stop_words:
					if i[1].find("JJ") != -1:
						pos_score, neg_score = 0, 0
						synsets_of_adjective = cv.senti_synsets(i[0], 'a') #Raghav change 'cv.senti_synsets(i[0], 'a')' to 'cv.senti_synsets(i[0])'
						print("Checking: ")
						print(synsets_of_adjective)
						if synsets_of_adjective:
							synsets_of_adjective = cv.senti_synsets(i[0])
							# list(synsets_of_adjective)
							# print(len(list(synsets_of_adjective)))
						for synset in synsets_of_adjective:
							print(synset.pos_score)
							print("Checking2: ")
							print(synsets_of_adjective)
							pos_score = pos_score + synset.pos_score#/len(synsets_of_adjective)
							neg_score = neg_score + synset.neg_score#/len(synsets_of_adjective)
						if pos_score > 0 or neg_score > 0:
							if reverse_polarity:
								overall_pos_score.append(neg_score)
								overall_neg_score.append(pos_score)
								reverse_polarity= False
							else:
								overall_pos_score.append(pos_score)
								overall_neg_score.append(neg_score)
					elif i[0] in negation_list:
						reverse_polarity = True

				if len(overall_neg_score) == 0:
					overall_neg_score.append(0)
				if len(overall_pos_score) == 0:
					overall_pos_score.append(0)


				for name in feature_name:
					if name in feature_score: #Raghav change 'if feature_score.has_key(name)' to 'if name in feature_score.has_key'
						posi_score, negi_score = feature_score[name][0], feature_score[name][1]
						feature_score[name] = (posi_score + sum(overall_pos_score)/len(overall_pos_score),
							negi_score + sum(overall_neg_score)/len(overall_neg_score))
					else:
						feature_score[name] = (sum(overall_pos_score)/len(overall_pos_score),
											sum(overall_neg_score)/len(overall_neg_score))

			for name, score in feature_score.items():   #Raghav change iteritems to items
				print(name + " : " + str(score))
				try:
					if score[1] > 0.1 or score[0] > 0.1:
						if score[0] > score[1]:
								review_category[name]['pos_review'] += 1
								pos_sum = pos_sum + 1
						elif score[1] > score[0]:
							review_category[name]['neg_review'] += 1
							neg_sum=neg_sum+1
						else:
							review_category[name]['neutral_review'] += 1
							neu_sum=neu_sum+1
					else:
						review_category[name]['neutral_review'] += 1
				except KeyError:
					err_file.write(filename + "\t")
					err_file.write("name:  " +name+"\n"+repr(review_category) + "\n")
		final_file.write("Filename: "+ filename.split("/")[1].split('.')[0])
		final_file.write("\nProduct:  "+ product)
		final_file.write("\nNumber Of Reviews:   "+ repr(number_of_reviews))
		if len(review_category.keys()) == 0:
			final_file.write("\nFeature List: No Features Found \n" )
		else:
			final_file.write("\nFeature List:" +repr(review_category) + "\n")
		final_file.write("\n\n")
	print ("")
	# Raghav change 'raw_input' with 'input'
	print("Review Processing Complete. An output file with the name 'output.txt' has been created in the current directory. Press any key to continue...")
	err_file.close()
	final_file.close()
	############################################################################################################################################

	d = Drawing(21 * cm, 29.7 * cm)
	pc = Pie()
	pc.x = 200
	pc.y = 150
	pc.width = 220
	pc.height = 220
	pc.data = [pos_sum, neg_sum, neu_sum]
	pc.labels = ['Positive', 'Negative', 'Neutral']
	pc.slices.strokeWidth = 0.5
	pc.slices[1].popout = 6

	d.add(pc)
	fon = 22
	print(product)
	d.add(String(14, 670, 'Product Name: ' + product[:42], fontSize=fon))
	count = int(len(product) / 41) - 1
	if (len(product) % 41 != 0):
		count += 1
	for i in range(1, count + 1):
		d.add(String(14, 670 - i * 30, '                        ' + product[(42 * i):(42 * i + 42)], fontSize=fon))
	pr=pos_sum*100/(pos_sum+neg_sum+neu_sum)
	d.add(String(14, 580 - count * 30, 'Number of Positive Features: ' + str(pos_sum), fontSize=fon))
	d.add(String(14, 550 - count * 30, 'Number of Negative Features: ' + str(neg_sum), fontSize=fon))
	d.add(String(14, 520 - count * 30, 'Number of Neutral Features: ' + str(neu_sum), fontSize=fon))
	d.add(String(14, 490 - count * 30, 'Rating: ' + str(pr), fontSize=fon))
	renderPDF.drawToFile(d, product[:10] + '.pdf', '           Review Report')

